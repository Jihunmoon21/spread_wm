#!/usr/bin/env python
"""
í•™ìŠµ ë°ì´í„° ë¡œë”ì—ì„œ ì‹¤ì œë¡œ ì–´ë–¤ ì´ë¯¸ì§€ê°€ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from datasets.libero_dset import load_libero_slice_train_val
from datasets.img_transforms import default_transform

print("=" * 60)
print("í•™ìŠµ ë°ì´í„° ë¡œë” í™•ì¸")
print("=" * 60)

# Dataset ìƒì„± (í•™ìŠµ ì‹œì™€ ë™ì¼í•œ ë°©ì‹)
print("\n1. ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
data_path = "/home/jihoonmun/LIBERO/libero/datasets_processed/libero_object"
transform = default_transform(img_size=256)

train_dset, val_dset = load_libero_slice_train_val(
    transform=transform,
    data_path=data_path,
    train_fraction=0.9,
    random_seed=42,
    num_frames=10,  # num_hist + num_pred
    frameskip=1,
    main_view='third_image'
)

print(f"  Train dataset type: {type(train_dset)}")
print(f"  Val dataset type: {type(val_dset)}")

# dictë¡œ ë°˜í™˜ë˜ë¯€ë¡œ 'train' í‚¤ë¡œ ì ‘ê·¼
if isinstance(train_dset, dict):
    actual_train_dset = train_dset  # ì´ë¯¸ dict
    print(f"  Dataset keys: {train_dset.keys()}")
    # DataLoaderë¥¼ ë§Œë“¤ì–´ì•¼ í•˜ì§€ë§Œ, ê°„ë‹¨íˆ í•˜ë‚˜ì˜ ìƒ˜í”Œë§Œ í™•ì¸
    # ëŒ€ì‹  LiberoDatasetì„ ì§ì ‘ ìƒì„±
    from datasets.libero_dset import LiberoDataset
    direct_dset = LiberoDataset(
        data_path="/home/jihoonmun/LIBERO/libero/datasets_processed/libero_object",
        transform=transform,
        main_view='third_image',
        normalize=True,
        num_frames=10,
        frameskip=1
    )
    train_dset = direct_dset

print(f"  Actual dataset size: {len(train_dset)}")

# ì²« ë²ˆì§¸ ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°
print("\n2. ì²« ë²ˆì§¸ ë°°ì¹˜ ë¡œë“œ ì¤‘...")
sample = train_dset[0]
if sample is None:
    print("  ERROR: Sample is None!")
    sys.exit(1)

obs, actions, state, meta = sample

print(f"  Visual shape: {obs['visual'].shape}")  # (T, C, H, W)
print(f"  Proprio shape: {obs['proprio'].shape}")
print(f"  Actions shape: {actions.shape}")

# ì²« ë²ˆì§¸ í”„ë ˆì„ ì¶”ì¶œ ë° ì €ì¥
print("\n3. ì´ë¯¸ì§€ ì €ì¥ ì¤‘...")
first_frame = obs['visual'][0]  # (C, H, W)

# Denormalize (í•™ìŠµ ì‹œ Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) ì ìš©ë¨)
first_frame = first_frame * 0.5 + 0.5  # [-1, 1] -> [0, 1]
first_frame = torch.clamp(first_frame, 0, 1)

# (C, H, W) -> (H, W, C) for matplotlib
first_frame_np = first_frame.permute(1, 2, 0).cpu().numpy()

# ì €ì¥
plt.imsave('training_data_frame0.png', first_frame_np)
plt.imsave('training_data_frame0_flipped.png', np.flipud(first_frame_np))

print("  âœ… Saved:")
print("     - training_data_frame0.png (í•™ìŠµ ë°ì´í„° ì›ë³¸)")
print("     - training_data_frame0_flipped.png (flip ë²„ì „)")
print("\n" + "=" * 60)
print("ğŸ‘€ ë‘ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”:")
print("   - í•™ìŠµ ë°ì´í„°ê°€ ì •ìƒ ë°©í–¥ì´ë©´: training_data_frame0.pngê°€ ì˜¬ë°”ë¥¸ ë°©í–¥")
print("   - í•™ìŠµ ë°ì´í„°ê°€ flipëœ ë°©í–¥ì´ë©´: training_data_frame0_flipped.pngê°€ ì˜¬ë°”ë¥¸ ë°©í–¥")
print("=" * 60)

